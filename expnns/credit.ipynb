{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments on the German Credit datasets\n",
    "Old version: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
    "Corrected version: https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29 / https://www.kaggle.com/c/south-german-credit-prediction/overview/data-overview\n",
    "\n",
    "Some meanings of the discrete/ordinal feature values in the old version were wrong.\n",
    "For example, for feature \"checking status\",\n",
    "\n",
    "(inferred by the old dataset) a data object's value is                    '1' in the old dataset meaning negative DM.\n",
    "(by new dataset) However, it should have been value          '4' in the old dataset meaning no checking account\n",
    "\n",
    "(inferred by the old dataset) a data object's value is                    **'2' in the new dataset** *meaning negative DM*\n",
    "(by new dataset) However, it should have been value          '1' in the old dataset meaning no checking account\n",
    "\n",
    "Whether using the encoding scheme in the old or the new dataset, the feature value should be corrected according to the true meaning. The procedures in this experiment are:\n",
    "1. Encode the dataset using the new dataset's meaning,\n",
    "2. According to the *meanings of the old dataset*, **find encoded number in the new dataset and modify the feature values**.\n",
    "3. Train first on the data points by *meanings of the old dataset* to get the base NN\n",
    "4. gradually train on the data points by meanings of the new dataset to get the shifted NNs.\n",
    "\n",
    "- Q here regardless of the experiments we are doing: this does not make much sense, if we spotted some error in the dataset, why don't we retrain the model on the corrected dataset??"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Python Standard Libraries\n",
    "import time\n",
    "import os, sys, pickle, json, math, time, multiprocessing, warnings, itertools, random, warnings, gc, ast, subprocess\n",
    "import copy\n",
    "from collections import defaultdict, Counter, namedtuple\n",
    "from math import log\n",
    "from itertools import product, combinations\n",
    "from random import choice, choices, sample, seed\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Multi-processing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# sci-kit learn\n",
    "import sklearn\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve\n",
    "\n",
    "if sklearn.__version__ >= '0.20':\n",
    "    from sklearn.naive_bayes import CategoricalNB\n",
    "    from sklearn.metrics import jaccard_score, balanced_accuracy_score\n",
    "else:\n",
    "    print('WARNING! Old version of sklearn, can\\'t load CategoricalNB.')\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 150\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process the old version dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     status  duration  history  purpose  amount  savings  employment  rate  \\\n",
      "0         1         6        4        3    1169        0           4     4   \n",
      "1         2        48        2        3    5951        1           2     2   \n",
      "2         0        12        4        6    2096        1           3     2   \n",
      "3         1        42        2        2    7882        1           3     2   \n",
      "4         1        24        3        0    4870        1           2     3   \n",
      "..      ...       ...      ...      ...     ...      ...         ...   ...   \n",
      "995       0        12        2        2    1736        1           3     3   \n",
      "996       1        30        2        1    3857        1           2     4   \n",
      "997       0        12        2        3     804        1           4     4   \n",
      "998       1        45        2        3    1845        1           2     4   \n",
      "999       2        45        4        1    4576        2           0     3   \n",
      "\n",
      "     sex  guarantors  residence  property  age  installment  housing  \\\n",
      "0      2           0          4         0   67            2        1   \n",
      "1      1           0          2         0   22            2        1   \n",
      "2      2           0          3         0   49            2        1   \n",
      "3      2           2          4         1   45            2        2   \n",
      "4      2           0          4         3   53            2        2   \n",
      "..   ...         ...        ...       ...  ...          ...      ...   \n",
      "995    1           0          4         0   31            2        1   \n",
      "996    0           0          4         1   40            2        1   \n",
      "997    2           0          4         2   38            2        1   \n",
      "998    2           0          4         3   23            2        2   \n",
      "999    2           0          4         2   27            2        1   \n",
      "\n",
      "     existing  job  liable  phone  foreign  good-credit  \n",
      "0           2    2       1      1        0            1  \n",
      "1           1    2       1      0        0            0  \n",
      "2           1    1       2      0        0            1  \n",
      "3           1    2       2      0        0            1  \n",
      "4           2    2       2      0        0            0  \n",
      "..        ...  ...     ...    ...      ...          ...  \n",
      "995         1    1       1      0        0            1  \n",
      "996         1    3       1      1        0            1  \n",
      "997         1    2       1      0        0            1  \n",
      "998         1    2       1      1        0            0  \n",
      "999         1    2       1      0        0            1  \n",
      "\n",
      "[1000 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/credit/old/german.data\", header=None, delimiter=',')\n",
    "df = df.dropna()\n",
    "df.columns = [\"status\", \"duration\", \"history\", \"purpose\", \"amount\", \"savings\", \"employment\", \"rate\", \"sex\", \"guarantors\",\n",
    "           \"residence\", \"property\", \"age\", \"installment\", \"housing\", \"existing\", \"job\", \"liable\", \"phone\", \"foreign\", \"good-credit\"]\n",
    "df = df.replace(to_replace=\n",
    "                {'status': {'A14': int(0), 'A11': int(1), 'A12': int(2), 'A13':int(3)},\n",
    "                 'history': {'A30': int(0), 'A31': int(1), 'A32': int(2), 'A33': int(3), 'A34': int(4)},\n",
    "                 'purpose': {'A40': int(0), 'A41': int(1),'A42': int(2),'A43': int(3),'A44': int(4),'A45': int(5),'A46': int(6),'A47': int(7),'A48': int(8),'A49': int(9),'A410': int(10),},\n",
    "                 'savings': {'A65': int(0),'A61': int(1),'A62': int(2),'A63': int(3),'A64': int(4),},\n",
    "                 'employment': {'A71': int(0),'A72': int(1),'A73': int(2),'A74': int(3),'A75': int(4),},\n",
    "                 'sex': {'A91': int(0),'A92': int(1),'A93': int(2),'A94': int(3),'A95': int(4)},\n",
    "                 'guarantors': {'A101': int(0),'A102': int(1),'A103': int(2)},\n",
    "                 'property': {'A121': int(0),'A122': int(1),'A123': int(2),'A124': int(3)},\n",
    "                 'installment': {'A141': int(0),'A142': int(1),'A143': int(2)},\n",
    "                 'housing': {'A151': int(0),'A152': int(1),'A153': int(2)},\n",
    "                 'job': {'A171': int(0),'A172': int(1),'A173': int(2),'A174': int(3)},\n",
    "                 'phone': {'A191': int(0),'A192': int(1)},\n",
    "                 'foreign': {'A201': int(0),'A202': int(1)},\n",
    "                 'good-credit': {1: int(1),2: int(0)},\n",
    "                 })\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "ordinal_features = {\"status\": 4, \"history\": 5, \"savings\": 5, \"employment\": 5, \"guarantors\": 3, \"job\": 4}\n",
    "discrete_features = {\"purpose\": 11, \"sex\": 5, \"property\": 4, \"installment\": 3, \"housing\": 3, \"phone\": 2, \"foreign\": 2}\n",
    "continuous_features = [\"duration\", \"amount\", \"rate\", \"residence\", \"age\", \"existing\", \"liable\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status 4\n",
      "[0 1 2 3]\n",
      "duration 33\n",
      "history 5\n",
      "[0 1 2 3 4]\n",
      "purpose 10\n",
      "[ 0  1  2  3  4  5  6  8  9 10]\n",
      "amount 921\n",
      "savings 5\n",
      "[0 1 2 3 4]\n",
      "employment 5\n",
      "[0 1 2 3 4]\n",
      "rate 4\n",
      "sex 4\n",
      "[0 1 2 3]\n",
      "guarantors 3\n",
      "[0 1 2]\n",
      "residence 4\n",
      "property 4\n",
      "[0 1 2 3]\n",
      "age 53\n",
      "installment 3\n",
      "[0 1 2]\n",
      "housing 3\n",
      "[0 1 2]\n",
      "existing 4\n",
      "job 4\n",
      "[0 1 2 3]\n",
      "liable 2\n",
      "phone 2\n",
      "[0 1]\n",
      "foreign 2\n",
      "[0 1]\n",
      "good-credit 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(21):\n",
    "    print(df.columns[i], len(np.unique(df.values[:, i])))\n",
    "    if df.columns[i] in ordinal_features or df.columns[i] in discrete_features:\n",
    "        print(np.unique(df.values[:, i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}